# üê≥ Docker –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

## –û–±–∑–æ—Ä

–ü—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Docker –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏–∏ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤, —á—Ç–æ –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏—è, –ø—Ä–æ—Å—Ç–æ—Ç—É —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å.

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Docker —Ñ–∞–π–ª–æ–≤

```
docker/
‚îú‚îÄ‚îÄ docker-compose.yml          # –û—Å–Ω–æ–≤–Ω–æ–π compose —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ docker-compose.prod.yml     # Production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ docker-compose.dev.yml      # Development –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Backend –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Frontend –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
‚îú‚îÄ‚îÄ mobile/
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Mobile build –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
‚îú‚îÄ‚îÄ nginx/
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf              # Nginx –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ ssl/                    # SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
‚îî‚îÄ‚îÄ postgres/
    ‚îú‚îÄ‚îÄ init.sql                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
    ‚îî‚îÄ‚îÄ postgresql.conf         # PostgreSQL –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
```

## –û—Å–Ω–æ–≤–Ω–æ–π docker-compose.yml

```yaml
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:14-alpine
    container_name: stroke_postgres
    environment:
      POSTGRES_DB: stroke_platform
      POSTGRES_USER: stroke_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf
    ports:
      - "5432:5432"
    networks:
      - stroke_network
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: stroke_redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - stroke_network
    restart: unless-stopped

  # Backend API
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: stroke_backend
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://stroke_user:${POSTGRES_PASSWORD}@postgres:5432/stroke_platform
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - FIREBASE_API_KEY=${FIREBASE_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    ports:
      - "3000:3000"
    depends_on:
      - postgres
      - redis
    networks:
      - stroke_network
    restart: unless-stopped
    volumes:
      - ./backend/logs:/app/logs

  # Frontend Web App
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: stroke_frontend
    environment:
      - REACT_APP_API_URL=http://localhost:3000/v1
      - REACT_APP_ENV=production
    ports:
      - "3001:80"
    depends_on:
      - backend
    networks:
      - stroke_network
    restart: unless-stopped

  # Nginx Reverse Proxy
  nginx:
    image: nginx:alpine
    container_name: stroke_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - frontend_build:/usr/share/nginx/html
    depends_on:
      - frontend
      - backend
    networks:
      - stroke_network
    restart: unless-stopped

  # Monitoring - Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: stroke_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - stroke_network
    restart: unless-stopped

  # Monitoring - Grafana
  grafana:
    image: grafana/grafana:latest
    container_name: stroke_grafana
    ports:
      - "3002:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - stroke_network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
  frontend_build:

networks:
  stroke_network:
    driver: bridge
```

## Backend Dockerfile

```dockerfile
# Multi-stage build –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞
FROM node:18-alpine AS builder

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ package files
COPY package*.json ./
COPY tsconfig*.json ./

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN npm ci --only=production && npm cache clean --force

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞
COPY src/ ./src/

# –°–±–æ—Ä–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
RUN npm run build

# Production stage
FROM node:18-alpine AS production

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ package files
COPY package*.json ./

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–æ–ª—å–∫–æ production –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN npm ci --only=production && npm cache clean --force

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY --from=builder /app/dist ./dist

# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ª–æ–≥–æ–≤
RUN mkdir -p /app/logs && chown -R nestjs:nodejs /app

# –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è nestjs
USER nestjs

# –û—Ç–∫—Ä—ã—Ç–∏–µ –ø–æ—Ä—Ç–∞
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
CMD ["node", "dist/main.js"]
```

## Frontend Dockerfile

```dockerfile
# Multi-stage build
FROM node:18-alpine AS builder

WORKDIR /app

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ package files
COPY package*.json ./

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
RUN npm ci

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞
COPY . .

# –°–±–æ—Ä–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
RUN npm run build

# Production stage
FROM nginx:alpine AS production

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—Ä–∞–Ω–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
COPY --from=builder /app/build /usr/share/nginx/html

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ nginx –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
COPY nginx.conf /etc/nginx/conf.d/default.conf

# –û—Ç–∫—Ä—ã—Ç–∏–µ –ø–æ—Ä—Ç–∞
EXPOSE 80

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1

# –ó–∞–ø—É—Å–∫ nginx
CMD ["nginx", "-g", "daemon off;"]
```

## Nginx –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```nginx
# nginx/nginx.conf
upstream backend {
    server backend:3000;
}

upstream frontend {
    server frontend:80;
}

# Rate limiting
limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

server {
    listen 80;
    server_name localhost;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # API routes
    location /api/ {
        limit_req zone=api burst=20 nodelay;
        
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # CORS headers
        add_header Access-Control-Allow-Origin *;
        add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
        add_header Access-Control-Allow-Headers "DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization";
        
        if ($request_method = 'OPTIONS') {
            add_header Access-Control-Allow-Origin *;
            add_header Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS";
            add_header Access-Control-Allow-Headers "DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization";
            add_header Access-Control-Max-Age 1728000;
            add_header Content-Type 'text/plain; charset=utf-8';
            add_header Content-Length 0;
            return 204;
        }
    }

    # Login endpoint with stricter rate limiting
    location /api/auth/login {
        limit_req zone=login burst=5 nodelay;
        
        proxy_pass http://backend;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Frontend routes
    location / {
        proxy_pass http://frontend;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }

    # Static files caching
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        proxy_pass http://frontend;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # Health check endpoint
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}

# SSL configuration (for production)
server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;

    # HSTS
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;

    # Same configuration as HTTP server
    # ... (copy from above)
}
```

## Production docker-compose.prod.yml

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:14-alpine
    container_name: stroke_postgres_prod
    environment:
      POSTGRES_DB: stroke_platform
      POSTGRES_USER: stroke_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/postgresql.conf:/etc/postgresql/postgresql.conf
    networks:
      - stroke_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  redis:
    image: redis:7-alpine
    container_name: stroke_redis_prod
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - stroke_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: stroke_backend_prod
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://stroke_user:${POSTGRES_PASSWORD}@postgres:5432/stroke_platform
      - REDIS_URL=redis://:${REDIS_PASSWORD}@redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - FIREBASE_API_KEY=${FIREBASE_API_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - postgres
      - redis
    networks:
      - stroke_network
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: stroke_frontend_prod
    environment:
      - REACT_APP_API_URL=https://api.stroke-support.com/v1
      - REACT_APP_ENV=production
    depends_on:
      - backend
    networks:
      - stroke_network
    restart: always
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  nginx:
    image: nginx:alpine
    container_name: stroke_nginx_prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - stroke_network
    restart: always
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  stroke_network:
    driver: bridge
```

## Development docker-compose.dev.yml

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:14-alpine
    container_name: stroke_postgres_dev
    environment:
      POSTGRES_DB: stroke_platform_dev
      POSTGRES_USER: stroke_user
      POSTGRES_PASSWORD: dev_password
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - stroke_network

  redis:
    image: redis:7-alpine
    container_name: stroke_redis_dev
    ports:
      - "6379:6379"
    networks:
      - stroke_network

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    container_name: stroke_backend_dev
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://stroke_user:dev_password@postgres:5432/stroke_platform_dev
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=dev_jwt_secret
    ports:
      - "3000:3000"
    volumes:
      - ./backend:/app
      - /app/node_modules
    depends_on:
      - postgres
      - redis
    networks:
      - stroke_network
    command: npm run start:dev

volumes:
  postgres_dev_data:

networks:
  stroke_network:
    driver: bridge
```

## Backend Dockerfile –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

```dockerfile
# Dockerfile.dev
FROM node:18-alpine

WORKDIR /app

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
COPY package*.json ./
RUN npm install

# –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∫–æ–¥–∞
COPY . .

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ nodemon –¥–ª—è hot reload
RUN npm install -g nodemon

# –û—Ç–∫—Ä—ã—Ç–∏–µ –ø–æ—Ä—Ç–∞
EXPOSE 3000

# –ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
CMD ["npm", "run", "start:dev"]
```

## –°–∫—Ä–∏–ø—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è

### start.sh
```bash
#!/bin/bash

# –ó–∞–ø—É—Å–∫ development –æ–∫—Ä—É–∂–µ–Ω–∏—è
echo "–ó–∞–ø—É—Å–∫ development –æ–∫—Ä—É–∂–µ–Ω–∏—è..."
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d

echo "–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–∏—Å–æ–≤..."
sleep 10

echo "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π..."
docker-compose exec backend npm run migration:run

echo "Development –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ!"
echo "Backend: http://localhost:3000"
echo "Frontend: http://localhost:3001"
echo "PostgreSQL: localhost:5432"
echo "Redis: localhost:6379"
```

### deploy.sh
```bash
#!/bin/bash

# Production –¥–µ–ø–ª–æ–π
echo "–ó–∞–ø—É—Å–∫ production –¥–µ–ø–ª–æ—è..."

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
docker-compose -f docker-compose.yml -f docker-compose.prod.yml down

# –°–±–æ—Ä–∫–∞ –Ω–æ–≤—ã—Ö –æ–±—Ä–∞–∑–æ–≤
docker-compose -f docker-compose.yml -f docker-compose.prod.yml build

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–æ–≤
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

echo "–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–∏–≥—Ä–∞—Ü–∏–π..."
docker-compose -f docker-compose.yml -f docker-compose.prod.yml exec backend npm run migration:run

echo "Production –¥–µ–ø–ª–æ–π –∑–∞–≤–µ—Ä—à–µ–Ω!"
```

### backup.sh
```bash
#!/bin/bash

# Backup –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
echo "–°–æ–∑–¥–∞–Ω–∏–µ backup –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö..."

BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="stroke_platform_${DATE}.sql"

mkdir -p $BACKUP_DIR

docker-compose exec postgres pg_dump -U stroke_user stroke_platform > "${BACKUP_DIR}/${BACKUP_FILE}"

echo "Backup —Å–æ–∑–¥–∞–Ω: ${BACKUP_DIR}/${BACKUP_FILE}"
```

## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```yaml
# –î–æ–±–∞–≤–∏—Ç—å –≤ docker-compose.yml
logging:
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"
```

### Health checks
```yaml
# –ü—Ä–∏–º–µ—Ä health check –¥–ª—è backend
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s
```

## –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è

### .env.example
```env
# Database
POSTGRES_PASSWORD=your_secure_password
REDIS_PASSWORD=your_redis_password

# JWT
JWT_SECRET=your_super_secret_jwt_key

# External APIs
FIREBASE_API_KEY=your_firebase_key
FIREBASE_PROJECT_ID=your_project_id
TWILIO_ACCOUNT_SID=your_twilio_sid
TWILIO_AUTH_TOKEN=your_twilio_token
OPENAI_API_KEY=your_openai_key

# Monitoring
GRAFANA_PASSWORD=your_grafana_password

# SSL (for production)
SSL_CERT_PATH=/etc/nginx/ssl/cert.pem
SSL_KEY_PATH=/etc/nginx/ssl/key.pem
```

---
*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 14.09.2025*
